var documenterSearchIndex = {"docs":
[{"location":"api/#API-1","page":"API","title":"API","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"Pages = [\"api.md\"]\nModule = [\"SparseGaussianProcesses\"]","category":"page"},{"location":"api/#","page":"API","title":"API","text":"Modules = [SparseGaussianProcesses]","category":"page"},{"location":"#SparseGaussianProcesses.jl-1","page":"Home","title":"SparseGaussianProcesses.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"┌───────────────────────────────────────┐  │⠀⠠⣤⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⡠⠤⢄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│  │⠀⠀⠀⢙⣦⣤⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⠀⢀⠜⠀⣀⣀⠑⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│  │⠀⢀⠵⡱⠁⣧⠈⢷⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⢠⣮⡶⢟⣖⡞⢍⣪⣆⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│  │⠀⢸⣶⠭⣈⠈⡷⡈⣧⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⢠⣾⠾⢍⢟⣿⣿⣿⣝⡿⣞⢆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│  │⠀⢠⢷⢷⡾⣿⣿⣷⠺⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⢀⣿⢋⣲⢟⡝⡲⠛⠻⣿⣌⣾⣞⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│  │⠀⠨⢵⣔⣻⡄⠹⣿⣗⣟⣦⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⣾⣯⡺⣯⠿⡻⠫⢍⡒⢜⢿⣿⡽⣷⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│  │⠀⠈⡡⠒⠊⢹⣷⠻⡯⣟⣷⢧⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⣼⣿⣽⣿⡟⡰⠁⢀⡠⠜⠺⡢⣿⣿⣿⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│  │⠀⠘⠊⠉⣩⠝⠙⣽⣫⢿⣿⡎⢇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣷⡿⣻⢻⣿⢖⠥⠚⠁⠀⠀⠀⠈⠳⣿⣿⣿⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│  │⠀⠀⡠⠎⠀⠀⠀⠘⡿⣇⢻⣽⡈⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⠔⠁⣿⣻⣣⡿⠉⠁⠀⠀⠀⠀⠀⠀⠀⠀⢫⣿⣿⣿⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│  │⠀⠈⠀⠀⠀⠀⠀⠀⠱⣽⣏⣿⣧⣼⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡰⠊⠀⣸⣿⣟⣷⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⡞⣿⢾⣿⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│  │⠒⠒⠒⠒⠒⠒⠒⠒⠒⠚⣿⣻⣿⣷⣻⣖⠒⠒⠒⠒⠒⠒⠒⠒⠒⡲⠓⠒⢲⣿⡿⣾⠓⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠚⣿⣞⣿⣷⡒⠒⠒⠒⠒⠒⠒⠒⠒⠒│  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠸⣷⣿⡿⡷⡧⣣⠀⠀⠀⠀⠀⠀⠀⢰⠁⠀⢰⣿⢷⣟⠎⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢹⢿⣿⣯⣿⠒⠒⠤⡀⠀⠀⠀⠀⠀│  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢫⣿⣿⣿⣸⣣⠱⡀⠀⠀⠀⠀⢰⠁⠀⢠⣿⢏⣟⡟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢟⣿⣿⣿⣧⠀⠀⠈⠢⡄⠀⠀⠀│  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⡞⣿⣿⣷⣻⢆⠱⡀⠀⠀⢀⠇⠀⣠⣷⡿⡿⡝⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⣵⣿⣿⡻⣧⠀⠀⠀⠘⡄⠀⠀│  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⣿⣿⣻⣿⡿⣏⠘⡌⢈⠎⠈⣜⣿⣿⣽⡱⠁⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢹⡿⣿⢿⣻⡯⡈⠀⠀⢸⡄⠀│  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠐⣶⣶⣶⢶⣰⢆⢐⢶⡠⢂⣶⣶⣖⡖⠀⠀⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢶⢲⡶⣶⣶⣆⠢⢤⢦⠄⠀│  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢹⢳⣻⣿⣟⣷⣿⣊⣱⣾⣿⡟⡞⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⡆⠻⡽⡿⣿⣆⣎⢎⠄⠀│  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⢗⠻⣿⣿⡿⣿⡻⡾⡻⡰⠁⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣄⠙⢾⣿⣗⣿⢗⡆⠀│  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⡼⡀⠈⢺⢝⠭⠜⡱⢡⠃⠀⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢏⠦⡀⠀⣛⠿⣿⠇⠀│  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⢳⡒⠁⠈⠉⠉⢀⠇⠀⠀⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⡄⠈⠉⠀⢀⠏⠁⠀│  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⡄⠀⠀⢠⠃⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠸⡀⠀⢀⡜⠀⠀⠀│  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠒⠒⠁⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠒⠁⠀⠀⠀⠀│  └───────────────────────────────────────┘ ","category":"page"},{"location":"#","page":"Home","title":"Home","text":"A Flux-based package for sparse Gaussian process models in Julia.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"It supports models of the form","category":"page"},{"location":"#","page":"Home","title":"Home","text":"(f mathbin boldsymbolu)(cdot) = (mathcalAg)(cdot) + mathbfK_(cdot)z (mathbfK_zz + mathbfLambda)^-1 (boldsymbolu - (mathcalBg)(boldsymbolz) - boldsymbolepsilon)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"where gsimoperatornameGP(0 k), boldsymbolusimoperatornameN(boldsymbolmu mathbfSigma), boldsymbolepsilonsimoperatornameN(boldsymbol0 mathbfLambda), and mathcalA, mathcalB are inter-domain operators (currently only the identity operator is supported). This little-known formula defines a Gaussian process with precisely the correct mean and variance of a standard sparse Gaussian process. Using this approach, training is performed via doubly stochastic variational inference.","category":"page"},{"location":"#Installation-1","page":"Home","title":"Installation","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"pkg> add SparseGaussianProcesses","category":"page"},{"location":"#Example-1","page":"Home","title":"Example","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"using Flux\nusing SparseGaussianProcesses\n\ngp = SparseGaussianProcess(SquaredExponentialKernel(1))\nx = reshape(-5:0.1:5, (1,:)) |> collect\ny = sin.(x)\n\n(gp,x,y) = gpu.((gp,x,y))\n\nrand!(gp; num_samples = 16)\ngp(x)\n\nopt = ADAM()\ndataset = Iterators.repeated((x,y), 1000)\ncb = Flux.throttle(() -> @show(loss(gp,x,y)|>sum), 1)\n\nFlux.train!((x,y) -> loss(gp,x,y)|>sum, Flux.params(gp), dataset, opt; cb = cb)\n\nimport Plots\nplot_gp_intervals(gp, x, y)","category":"page"},{"location":"#Author-1","page":"Home","title":"Author","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Alexander Terenin (PhD student, Statistical Machine Learning, Imperial College London)","category":"page"},{"location":"#Citing-1","page":"Home","title":"Citing","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"@article{wilson20,\n\tAuthor = {James T. Wilson and Viacheslav Borovitskiy and Alexander Terenin and Peter Mostowski and Marc Peter Deisenroth},\n\tJournal = {arXiv:2002.09309},\n\tTitle = {Efficiently sampling functions from Gaussian process posteriors},\n\tYear = {2020}}\n","category":"page"}]
}
