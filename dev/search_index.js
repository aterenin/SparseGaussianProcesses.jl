var documenterSearchIndex = {"docs":
[{"location":"api/#API-1","page":"API","title":"API","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"Modules = [SparseGaussianProcesses]","category":"page"},{"location":"api/#SparseGaussianProcesses.CircularSquaredExponentialKernel","page":"API","title":"SparseGaussianProcesses.CircularSquaredExponentialKernel","text":"CircularSquaredExponentialKernel\n\nA squared exponential kernel on the circle, defined on the circle or, if  d  1, the d-dimensional torus. The expression is given by\n\nk(xx) = sum_n in 2pimathbbZ^d sigma^2expleft(             -leftlVertfracx - x + nkappa rightrVert^2 right)\n\nparameterized by log-variance ln(sigma^2) (trainable by default) and log-length-scales ln(kappa) (trainable by default) applied  element-wise to each dimension. The sum is computed to a specified truncation level.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.CircularSquaredExponentialKernel-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T}","page":"API","title":"SparseGaussianProcesses.CircularSquaredExponentialKernel","text":"(k::CircularSquaredExponentialKernel)(x1::AbstractMatrix, \n                                      x2::AbstractMatrix)\n\nComputes the kernel matrix for the given circular squared exponential kernel.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.CircularSquaredExponentialKernel-Tuple{Int64}","page":"API","title":"SparseGaussianProcesses.CircularSquaredExponentialKernel","text":"CircularSquaredExponentialKernel(dim::Int)\n\nCreates a squared exponential kernel defined on the circle, or more generally a  torus of dimension dim.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.EuclideanRandomFeatures","page":"API","title":"SparseGaussianProcesses.EuclideanRandomFeatures","text":"EuclideanRandomFeatures\n\nA set of Euclidean random features, parameterized by frequency and phase, together with a set of associated basis weights.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.EuclideanRandomFeatures-Tuple{AbstractArray{#s20,3} where #s20,GradientKernel{#s19} where #s19<:SparseGaussianProcesses.EuclideanKernel}","page":"API","title":"SparseGaussianProcesses.EuclideanRandomFeatures","text":"(self::EuclideanRandomFeatures)(x::AbstractArray{<:Any,3},w::AbstractMatrix, \n                                k::GradientKernel{<:EuclideanKernel})\n\nEvaluate (nabla g)(x) where g is a Gaussian process with kernel k, nabla is the gradient inter-domain operator, and x is the batched  data, using the random features.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.EuclideanRandomFeatures-Tuple{AbstractArray{T,2} where T,GradientKernel{#s22} where #s22<:SparseGaussianProcesses.EuclideanKernel}","page":"API","title":"SparseGaussianProcesses.EuclideanRandomFeatures","text":"(self::EuclideanRandomFeatures)(x::AbstractMatrix, w::AbstractMatrix, \n                                k::GradientKernel{<:EuclideanKernel})\n\nEvaluate (nabla g)(x) where g is a Gaussian process with kernel k, nabla is the gradient inter-domain operator, and x is the data, using the random features.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.EuclideanRandomFeatures-Tuple{AbstractArray{T,2} where T,SparseGaussianProcesses.EuclideanKernel}","page":"API","title":"SparseGaussianProcesses.EuclideanRandomFeatures","text":"(self::EuclideanRandomFeatures)(x::AbstractMatrix, w::AbstractMatrix, \n                                k::EuclideanKernel)\n\nEvaluate the f(x) where f is a Gaussian process with kernel k,  and x is the data, using the random features.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.EuclideanRandomFeatures-Tuple{SparseGaussianProcesses.EuclideanKernel,Int64}","page":"API","title":"SparseGaussianProcesses.EuclideanRandomFeatures","text":"EuclideanRandomFeatures(k::EuclideanKernel, num_features::Int)\n\nCreate a set of Euclidean random features with eigenvalues given by the  spectral distribution given by k.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.GradientKernel-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T}","page":"API","title":"SparseGaussianProcesses.GradientKernel","text":"(k::GradientKernel{<:SquaredExponentialKernel})(x1::AbstractMatrix, \n                                                x2::AbstractMatrix)\n\nComputes the kernel matrix for the given gradient squared exponential kernel.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.GradientOperator","page":"API","title":"SparseGaussianProcesses.GradientOperator","text":"GradientOperator\n\nThe gradient inter-domain operator mathcalAf = nabla f.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.IdentityOperator","page":"API","title":"SparseGaussianProcesses.IdentityOperator","text":"IdentityOperator\n\nThe identity inter-domain operator mathcalAf = f.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.MarginalInducingPoints","page":"API","title":"SparseGaussianProcesses.MarginalInducingPoints","text":"MarginalInducingPoints\n\nA set of inducing points representing the marginal value of the  Gaussian process u = (mathcalB g)(z).\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.MarginalInducingPoints-Tuple{AbstractArray{T,2} where T,SparseGaussianProcesses.Kernel}","page":"API","title":"SparseGaussianProcesses.MarginalInducingPoints","text":"(self::MarginalInducingPoints)(z::AbstractMatrix, k::Kernel)\n\nSets the inducing locations of u to z, inducing mean to zero, and inducing covariance to k(zz).\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.MarginalInducingPoints-Tuple{SparseGaussianProcesses.CovarianceKernel,Int64}","page":"API","title":"SparseGaussianProcesses.MarginalInducingPoints","text":"MarginalInducingPoints(k::CovarianceKernel, num_inducing::Integer)\n\nCreates a set of marginal inducing points with covariance kernel k of u.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.MarginalInducingPoints-Tuple{}","page":"API","title":"SparseGaussianProcesses.MarginalInducingPoints","text":"(self::MarginalInducingPoints)()\n\nAssembles the inducing covariance into upper-triangular form, with diagonal  values exponentiated to ensure they are positive. Returns inducing locations,  inducing mean, jitter covariance, and inducing covariance.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.NormalHyperprior","page":"API","title":"SparseGaussianProcesses.NormalHyperprior","text":"NormalHyperprior\n\nAn isotropic multivariate normal hyperprior, parameterized by mean and  element-wise standard deviation.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.NormalHyperprior-Tuple{AbstractArray{T,1} where T}","page":"API","title":"SparseGaussianProcesses.NormalHyperprior","text":"(hp::NormalHyperprior)(x::AbstractVector)\n\nEvaluates the normal hyperprior at x.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.SparseGaussianProcess","page":"API","title":"SparseGaussianProcesses.SparseGaussianProcess","text":"SparseGaussianProcess\n\nA sparse Gaussian process, with kernel kernel. It supports models of the form\n\n(f  u)(cdot) = (mathcalA g)(cdot) + K_(cdot)z                  (K_zz + Lambda)^-1 (u - (mathcalB g)(z) - epsilon)\n\nwhere g sim GP(0 k), u sim N(mu Sigma),  epsilon sim N(0 Lambda), and mathcalA, mathcalB  are inter-domain operators.\n\nFields\n\nkernel: the kernel k of g.\nobservation_operator: the observation operator mathcalA.\ninter_domain_operator: the inter-domain operator mathcalB.\nprior_basis: the basis and weights used for efficiently sampling the prior.\ninducing_points: the basis and weights used for sampling the data-dependent  portion of the GP.\nlog_error: the error variance (log-scale, trainable by default).\nhyperprior: the hyperprior used for the log error term.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.SparseGaussianProcess-Tuple{SparseGaussianProcesses.CovarianceKernel}","page":"API","title":"SparseGaussianProcesses.SparseGaussianProcess","text":"SparseGaussianProcess(k::CovarianceKernel)\n\nCreates a SparseGaussianProcess with kernel k, with 64 random features  and 10 inducing points by default.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.SquaredExponentialKernel","page":"API","title":"SparseGaussianProcesses.SquaredExponentialKernel","text":"SquaredExponentialKernel\n\nA squared exponential kernel\n\nk(xx) = sigma^2expleft( -leftlVertfracx - xkappa                                                       rightrVert^2 right)\n\nparameterized by log-variance ln(sigma^2) (trainable by default) and log-length-scales ln(kappa) (trainable by default) applied  element-wise to each dimension.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.SquaredExponentialKernel-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T}","page":"API","title":"SparseGaussianProcesses.SquaredExponentialKernel","text":"(k::SquaredExponentialKernel)(x1::AbstractMatrix, x2::AbstractMatrix)\n\nComputes the kernel matrix for the given squared exponential kernel.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.SquaredExponentialKernel-Tuple{Int64}","page":"API","title":"SparseGaussianProcesses.SquaredExponentialKernel","text":"SquaredExponentialKernel(dim::Int)\n\nCreates a squared exponential kernel of dimension dim.\n\n\n\n\n\n","category":"method"},{"location":"api/#Random.rand!-Tuple{EuclideanRandomFeatures,SparseGaussianProcesses.EuclideanKernel}","page":"API","title":"Random.rand!","text":"rand!(self::EuclideanRandomFeatures, k::EuclideanKernel, \n      num_features::Int = size(self.frequency,ndims(self.frequency)))\n\nDraw a new set of random features, by randomly sampling a new frequencies from the spectral measure, and new phases uniformly from (0 2pi). Does NOT automatically resample the GP containing the features.\n\n\n\n\n\n","category":"method"},{"location":"api/#Random.rand!-Tuple{SparseGaussianProcesses.GaussianProcess}","page":"API","title":"Random.rand!","text":"rand!(gp::GaussianProcess; num_samples = num_samples(gp))\n\nDraw a new set of samples from the Gaussian process.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.loss-Tuple{SparseGaussianProcesses.GaussianProcess,AbstractArray{T,2} where T,AbstractArray{T,2} where T}","page":"API","title":"SparseGaussianProcesses.loss","text":"loss(gp::GaussianProcess, x::AbstractMatrix, y::AbstractMatrix; \n                                             n_data::Int = size(x,ndims(x)))\n\nComputes the Kullback-Leibler divergence of the variational family from the  posterior Gaussian process, up to an additive constant. Minimizing this  function trains the Gaussian process.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.CircularKernel","page":"API","title":"SparseGaussianProcesses.CircularKernel","text":"CircularKernel\n\nAn abstract covariance kernel defined over a circle, or more generally a  d-dimensional torus.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.CovarianceKernel","page":"API","title":"SparseGaussianProcesses.CovarianceKernel","text":"CovarianceKernel\n\nA covariance kernel, assumed symmetric in its arguments.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.CrossCovarianceKernel","page":"API","title":"SparseGaussianProcesses.CrossCovarianceKernel","text":"CrossCovarianceKernel\n\nA cross-covariance kernel, NOT necessarily symmetric in its arguments.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.EuclideanKernel","page":"API","title":"SparseGaussianProcesses.EuclideanKernel","text":"EuclideanKernel\n\nAn abstract covariance kernel defined over a Euclidean space.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.GaussianProcess","page":"API","title":"SparseGaussianProcesses.GaussianProcess","text":"GaussianProcess\n\nAn abstract Gaussian process type.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.GaussianProcess-Tuple{AbstractArray{#s19,3} where #s19}","page":"API","title":"SparseGaussianProcesses.GaussianProcess","text":"(gp::GaussianProcess)(x::AbstractArray{<:Any,3})\n\nEvaluate gp at a batched set of points x. Returns a 3-array whose dimensions are ordered (output_dimension, data_point_index, batch_index).\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.GaussianProcess-Tuple{AbstractArray{T,2} where T}","page":"API","title":"SparseGaussianProcesses.GaussianProcess","text":"(gp::GaussianProcess)(x::AbstractMatrix)\n\nEvaluate gp at a set of points x. Returns a 3-array whose dimensions are ordered (output_dimension, data_point_index, sample_index).\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.Hyperprior","page":"API","title":"SparseGaussianProcesses.Hyperprior","text":"Hyperprior\n\nAn abstract hyperprior.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.InducingPoints","page":"API","title":"SparseGaussianProcesses.InducingPoints","text":"InducingPoints\n\nAn abstract set of inducing points.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.InterDomainOperator","page":"API","title":"SparseGaussianProcesses.InterDomainOperator","text":"InterDomainOperator\n\nAn abstract inter-domain operator.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.Kernel","page":"API","title":"SparseGaussianProcesses.Kernel","text":"Kernel\n\nAn abstract kernel.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.Kernel-Tuple{AbstractArray{#s21,3} where #s21,AbstractArray{T,2} where T}","page":"API","title":"SparseGaussianProcesses.Kernel","text":"(k::Kernel)(x1::AbstractArray{<:Any,3}, x2::AbstractMatrix)\n\nComputes a kernel matrix in batched form.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.LeftGradientKernel-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T}","page":"API","title":"SparseGaussianProcesses.LeftGradientKernel","text":"(k::LeftGradientKernel{<:SquaredExponentialKernel})(x1::AbstractMatrix, \n                                                    x2::AbstractMatrix)\n\nComputes the kernel matrix for the given gradient squared exponential  cross-covariance.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.PriorBasis","page":"API","title":"SparseGaussianProcesses.PriorBasis","text":"PriorBasis\n\nAn abstract basis used for sampling a prior Gaussian process, with weights.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.PseudoDataInducingPoints","page":"API","title":"SparseGaussianProcesses.PseudoDataInducingPoints","text":"PseudoDataInducingPoints\n\nA set of inducing points representing pseudo-data points with diagonal  non-constant error covariance.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.PseudoDataInducingPoints-Tuple{AbstractArray{T,2} where T,SparseGaussianProcesses.Kernel}","page":"API","title":"SparseGaussianProcesses.PseudoDataInducingPoints","text":"(self::PseudoDataInducingPoints)(z::AbstractMatrix, k::Kernel)\n\nSets the inducing locations of u to z, inducing mean to zero, and  inducing error variance to one for each pseudo-data point.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.PseudoDataInducingPoints-Tuple{SparseGaussianProcesses.Kernel,Int64,Int64}","page":"API","title":"SparseGaussianProcesses.PseudoDataInducingPoints","text":"PseudoDataInducingPoints(k::Kernel, dim::Int, num_inducing::Int)\n\nCreates a set of pseudo-data inducing points with unit error variance.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.PseudoDataInducingPoints-Tuple{}","page":"API","title":"SparseGaussianProcesses.PseudoDataInducingPoints","text":"(self::PseudoDataInducingPoints)()\n\nAssembles the pseudo-data inducing error variance into matrix form. Returns  inducing locations, inducing mean, nothing jitter term, and inducing error  variance.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.RightGradientKernel-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T}","page":"API","title":"SparseGaussianProcesses.RightGradientKernel","text":"(k::RightGradientKernel{<:SquaredExponentialKernel})(x1::AbstractMatrix, \n                                                     x2::AbstractMatrix)\n\nComputes the kernel matrix for the given gradient squared exponential  cross-covariance.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.num_samples-Tuple{SparseGaussianProcesses.GaussianProcess}","page":"API","title":"SparseGaussianProcesses.num_samples","text":"num_samples(gp::GaussianProcess)\n\nReturns the number of random samples currently stored in gp.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.pairwise_column_difference-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T}","page":"API","title":"SparseGaussianProcesses.pairwise_column_difference","text":"pairwise_column_difference(x::AbstractMatrix, y::AbstractMatrix)\n\nComputes the 3-dimensional distance array, where out dimensions  are (input_dimension, x_data_point_dimension, y_data_point_dimension).\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.prior_KL-Tuple{SparseGaussianProcess{#s19,#s18,#s17,#s16,#s15,V,H} where H<:SparseGaussianProcesses.Hyperprior where V<:(AbstractArray{T,1} where T) where #s15<:MarginalInducingPoints where #s16 where #s17 where #s18 where #s19}","page":"API","title":"SparseGaussianProcesses.prior_KL","text":"prior_KL(gp::SparseGaussianProcess{<:Any,<:Any,<:Any, <:Any,\n                                   <:MarginalInducingPoints})\n\nComputes the prior Kullback-Leibler divergence for a Gaussian process with marginal inducing points, given by the expression\n\nKL(q(u) mathbin p(u)) = frac12 left(                                                lnfracK_zzSigma +                                                tr(K_zz^-1Sigma) +                                                mu^T K_zz mu right)\n\nwhere the mean is re-parameterized according to  mu = mathbbE( (K_zz + xi I)^-1 u ).\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.spectral_distribution-Tuple{CircularSquaredExponentialKernel}","page":"API","title":"SparseGaussianProcesses.spectral_distribution","text":"spectral_distribution(k::CircularSquaredExponentialKernel, \n                      num_samples::Integer)\n\nDraws n samples from the spectral distribution of a standard squared exponential kernel on the circle.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.spectral_distribution-Tuple{SquaredExponentialKernel}","page":"API","title":"SparseGaussianProcesses.spectral_distribution","text":"spectral_distribution(k::SquaredExponentialKernel; num_samples::Integer)\n\nDraws n samples from the spectral distribution of a standard squared  exponential kernel, which is multivariate Gaussian with covariance 2 I.\n\n\n\n\n\n","category":"method"},{"location":"api/#Index-1","page":"API","title":"Index","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"Pages = [\"api.md\"]\nModule = [\"SparseGaussianProcesses\"]","category":"page"},{"location":"#[SparseGaussianProcesses.jl](http://github.com/aterenin/SparseGaussianProcesses.jl)-1","page":"Home","title":"SparseGaussianProcesses.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"┌───────────────────┐\n│⢰⢦⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡆⠀⠀⢀⣴⣶⢄⠀⠀⠀⠀⠀⠀⠀⠀│\n│⢨⣿⣷⣻⣵⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⣠⣾⣿⣿⣿⡆⠀⠀⠀⠀⠀⠀⠀│\n│⠨⡿⣿⣿⣿⣧⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⣼⣿⣿⠿⣿⣾⣿⡀⠀⠀⠀⠀⠀⠀│\n│⠸⠋⠑⢿⣿⣿⡆⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⡟⠉⠺⣻⣿⣧⠀⠀⠀⠀⠀⠀│\n│⠀⠀⠀⠀⠹⣿⣿⡀⠀⠀⠀⠀⠀⠀⣼⣿⣿⠝⠀⠀⠀⠈⢿⣿⡆⠀⠀⠀⠀⠀│\n│⠉⠉⠉⠉⠉⢻⣿⣯⠉⠉⠉⠉⠉⣹⣿⣿⠏⠉⠉⠉⠉⠉⠉⣿⣿⣍⡉⠉⠉⠉│\n│⠀⠀⠀⠀⠀⠀⢿⣿⡆⠀⠀⢀⣮⣿⣿⡏⠀⠀⠀⠀⠀⠀⠀⠸⣿⣏⢟⡄⡜⠀│\n│⠀⠀⠀⠀⠀⠀⠈⢿⣿⣦⣶⣫⣿⣿⡏⡇⠀⠀⠀⠀⠀⠀⠀⠀⠹⣿⣯⣫⣦⠂│\n│⠀⠀⠀⠀⠀⠀⠀⠘⢿⣿⣿⣿⡿⡟⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠹⣿⣿⣿⡄│\n│⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠾⠿⠏⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠹⢿⠿⠀│\n│⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠱⠀│\n└───────────────────┘","category":"page"},{"location":"#","page":"Home","title":"Home","text":"A Flux-based package for sparse Gaussian process models in Julia.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"It supports models of the form","category":"page"},{"location":"#","page":"Home","title":"Home","text":"(f mathbin boldsymbolu)(cdot) = (mathcalAg)(cdot) + mathbfK_(cdot)z (mathbfK_zz + mathbfLambda)^-1 (boldsymbolu - (mathcalBg)(boldsymbolz) - boldsymbolepsilon)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"where gsimoperatornameGP(0 k), boldsymbolusimoperatornameN(boldsymbolmu mathbfSigma), boldsymbolepsilonsimoperatornameN(boldsymbol0 mathbfLambda), and mathcalA, mathcalB are inter-domain operators (currently only the identity operator is supported). This little-known formula defines a Gaussian process with precisely the correct mean and covariance of a standard sparse Gaussian process, and can be used to obtain entire function draws which can be evaluated deterministically at arbitrary locations once sampled. Using this approach, training is performed via doubly stochastic variational inference.","category":"page"},{"location":"#Installation-1","page":"Home","title":"Installation","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"pkg> add SparseGaussianProcesses","category":"page"},{"location":"#Example-1","page":"Home","title":"Example","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"using Flux\nusing SparseGaussianProcesses\n\ngp = SparseGaussianProcess(SquaredExponentialKernel(1))\nx = reshape(-5:0.1:5, (1,:)) |> collect\ny = sin.(x)\n\n(gp,x,y) = gpu.((gp,x,y))\n\nrand!(gp; num_samples = 16)\ngp(x)\n\nopt = ADAM()\ndataset = Iterators.repeated((x,y), 1000)\ncb = Flux.throttle(() -> @show(loss(gp,x,y)|>sum), 1)\n\nFlux.train!((x,y) -> loss(gp,x,y)|>sum, Flux.params(gp), dataset, opt; cb = cb)\n\nimport Plots\nplot_gp_intervals(gp, x, y)","category":"page"},{"location":"#Author-1","page":"Home","title":"Author","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Alexander Terenin (PhD student, Statistical Machine Learning, Imperial College London)","category":"page"},{"location":"#Citing-1","page":"Home","title":"Citing","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"@article{wilson20,\n\tAuthor = {James T. Wilson and Viacheslav Borovitskiy and Alexander Terenin and Peter Mostowski and Marc Peter Deisenroth},\n\tJournal = {arXiv:2002.09309},\n\tTitle = {Efficiently sampling functions from Gaussian process posteriors},\n\tYear = {2020}}","category":"page"}]
}
