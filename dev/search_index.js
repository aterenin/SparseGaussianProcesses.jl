var documenterSearchIndex = {"docs":
[{"location":"api/#API-1","page":"API","title":"API","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"Modules = [SparseGaussianProcesses]","category":"page"},{"location":"api/#SparseGaussianProcesses.EuclideanRandomFeatures","page":"API","title":"SparseGaussianProcesses.EuclideanRandomFeatures","text":"EuclideanRandomFeatures\n\nA set of Euclidean random features, parameterized by frequency and phase, together with a set of associated basis weights.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.EuclideanRandomFeatures-Tuple{AbstractArray{T,2} where T,SparseGaussianProcesses.EuclideanKernel,IdentityOperator}","page":"API","title":"SparseGaussianProcesses.EuclideanRandomFeatures","text":"(self::EuclideanRandomFeatures)(x::AbstractMatrix, w::AbstractMatrix, k::EuclideanKernel, op::IdentityOperator)\n\nEvaluate the (mathcalAg)(boldsymbolx) where g is a Gaussian process with kernel k, mathcalA is an inter-domain operator, and boldsymbolx is the data, using the random features.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.EuclideanRandomFeatures-Tuple{SparseGaussianProcesses.EuclideanKernel,Int64}","page":"API","title":"SparseGaussianProcesses.EuclideanRandomFeatures","text":"EuclideanRandomFeatures(k::EuclideanKernel, num_features::Int)\n\nCreate a set of Euclidean random features with spectral distribution given by k.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.GradientOperator","page":"API","title":"SparseGaussianProcesses.GradientOperator","text":"GradientOperator\n\nThe gradient inter-domain operator mathcalAf = nabla f.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.IdentityOperator","page":"API","title":"SparseGaussianProcesses.IdentityOperator","text":"IdentityOperator\n\nThe identity inter-domain operator mathcalAf = f.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.MarginalInducingPoints","page":"API","title":"SparseGaussianProcesses.MarginalInducingPoints","text":"MarginalInducingPoints\n\nA set of inducing points representing the marginal value of the  Gaussian process boldsymbolu = (mathcalBg)(boldsymbolz).\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.MarginalInducingPoints-Tuple{AbstractArray{T,2} where T,SparseGaussianProcesses.Kernel}","page":"API","title":"SparseGaussianProcesses.MarginalInducingPoints","text":"(self::MarginalInducingPoints)(z::AbstractMatrix, k::Kernel)\n\nSets the inducing locations of boldsymbolu to boldsymbolz, inducing mean to zero, and inducing covariance to k(boldsymbolzboldsymbolz).\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.MarginalInducingPoints-Tuple{SparseGaussianProcesses.CovarianceKernel,Int64}","page":"API","title":"SparseGaussianProcesses.MarginalInducingPoints","text":"MarginalInducingPoints(k::CovarianceKernel, num_inducing::Integer)\n\nCreates a set of marginal inducing points with covariance kernel k of boldsymbolu.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.MarginalInducingPoints-Tuple{}","page":"API","title":"SparseGaussianProcesses.MarginalInducingPoints","text":"(self::MarginalInducingPoints)()\n\nAssembles the inducing covariance into upper-triangular form, with diagonal values exponentiated to ensure they are positive. Returns inducing locations, inducing mean, jitter covariance, and inducing covariance.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.NormalHyperprior","page":"API","title":"SparseGaussianProcesses.NormalHyperprior","text":"NormalHyperprior\n\nAn isotropic multivariate normal hyperprior, parameterized  by mean and element-wise standard deviation.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.NormalHyperprior-Tuple{AbstractArray{T,1} where T}","page":"API","title":"SparseGaussianProcesses.NormalHyperprior","text":"(hp::NormalHyperprior)(x::AbstractVector)\n\nEvaluates the normal hyperprior at boldsymbolx.`\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.SparseGaussianProcess","page":"API","title":"SparseGaussianProcesses.SparseGaussianProcess","text":"SparseGaussianProcess\n\nA sparse Gaussian process, with kernel kernel. It supports models of the form\n\n(f mathbin boldsymbolu)(cdot) = (mathcalAg)(cdot) + mathbfK_(cdot)z (mathbfK_zz + mathbfLambda)^-1 (boldsymbolu - (mathcalBg)(boldsymbolz) - boldsymbolepsilon)\n\nwhere gsimoperatornameGP(0 k), boldsymbolusimoperatornameN(boldsymbolmu mathbfSigma), boldsymbolepsilonsimoperatornameN(boldsymbol0 mathbfLambda), and mathcalA, mathcalB are inter-domain operators.\n\nFields\n\nkernel: the kernel k of g.\nobservation_operator: the observation operator mathcalA.\ninter_domain_operator: the inter-domain operator mathcalB.\nprior_basis: the basis and weights used for efficiently sampling the prior.\ninducing_points: the basis and weights used for sampling the data-dependent portion of the GP.\nlog_error: the error variance (log-scale, trainable by default).\nhyperprior: the hyperprior used for the log error term.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.SparseGaussianProcess-Tuple{SparseGaussianProcesses.CovarianceKernel}","page":"API","title":"SparseGaussianProcesses.SparseGaussianProcess","text":"SparseGaussianProcess(k::CovarianceKernel)\n\nCreates a SparseGaussianProcess with kernel k, with  64 random features and 10 inducing points by default.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.SquaredExponentialKernel","page":"API","title":"SparseGaussianProcesses.SquaredExponentialKernel","text":"SquaredExponentialKernel\n\nA squared exponential kernel\n\n``k(\\boldsymbol{x},\\boldsymbol{y}) = \\sigma^2\\exp\\left( -\\left\\lVert\\frac{\\boldsymbol{x} - \\boldsymbol{y}}{\\boldsymbol\\kappa} \\right\\rVert^2 \\right)\n\nparameterized by log-variance ln(sigma^2) (trainable by default) and log-length-scales ln(boldsymbolkappa) (trainable by default) applied  element-wise to each dimension.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.SquaredExponentialKernel-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T}","page":"API","title":"SparseGaussianProcesses.SquaredExponentialKernel","text":"(k::SquaredExponentialKernel)(x1::AbstractMatrix, x2::AbstractMatrix)\n\nComputes the kernel matrix for the given squared exponential kernel.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.SquaredExponentialKernel-Tuple{Int64}","page":"API","title":"SparseGaussianProcesses.SquaredExponentialKernel","text":"SquaredExponentialKernel(dim::Int)\n\nCreates a squared exponential kernel of dimension dim.\n\n\n\n\n\n","category":"method"},{"location":"api/#Random.rand!","page":"API","title":"Random.rand!","text":"rand!(self::EuclideanRandomFeatures, k::EuclideanKernel, num_features::Int = size(self.frequency,ndims(self.frequency)))\n\nDraw a new set of random features, by randomly sampling a new frequencies from the spectral measure, and new phases uniformly from (0 2pi). Does NOT automatically resample the GP containing the features.\n\n\n\n\n\n","category":"function"},{"location":"api/#Random.rand!-Tuple{SparseGaussianProcesses.GaussianProcess}","page":"API","title":"Random.rand!","text":"rand!(gp::GaussianProcess; num_samples = num_samples(gp))\n\nDraw a new set of samples from the Gaussian process.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.loss-Tuple{SparseGaussianProcesses.GaussianProcess,AbstractArray{T,2} where T,AbstractArray{T,2} where T}","page":"API","title":"SparseGaussianProcesses.loss","text":"loss(gp::GaussianProcess, x::AbstractMatrix, y::AbstractMatrix; n_data::Int = size(x,ndims(x)))\n\nComputes the Kullback-Leibler divergence of the variational family from the posterior Gaussian process, up to an additive constant. Minimizing this function trains the Gaussian process.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.CovarianceKernel","page":"API","title":"SparseGaussianProcesses.CovarianceKernel","text":"CovarianceKernel\n\nA covariance kernel, assumed symmetric in its arguments.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.CrossCovarianceKernel","page":"API","title":"SparseGaussianProcesses.CrossCovarianceKernel","text":"CrossCovarianceKernel\n\nA cross-covariance kernel, NOT necessarily symmetric in its arguments.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.EuclideanKernel","page":"API","title":"SparseGaussianProcesses.EuclideanKernel","text":"EuclideanKernel\n\nAn abstract covariance kernel defined over a Euclidean space.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.GaussianProcess","page":"API","title":"SparseGaussianProcesses.GaussianProcess","text":"GaussianProcess\n\nAn abstract Gaussian process type.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.GaussianProcess-Tuple{AbstractArray{T,2} where T}","page":"API","title":"SparseGaussianProcesses.GaussianProcess","text":"(gp::GaussianProcess)(x::AbstractMatrix)\n\nEvaluate gp at a set of points x. Returns a 3-array whose dimensions are ordered (output_dimension, data_point_index, sample_index).\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.Hyperprior","page":"API","title":"SparseGaussianProcesses.Hyperprior","text":"Hyperprior\n\nAn abstract hyperprior.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.InducingPoints","page":"API","title":"SparseGaussianProcesses.InducingPoints","text":"InducingPoints\n\nAn abstract set of inducing points.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.InterDomainOperator","page":"API","title":"SparseGaussianProcesses.InterDomainOperator","text":"InterDomainOperator\n\nAn abstract inter-domain operator.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.Kernel","page":"API","title":"SparseGaussianProcesses.Kernel","text":"Kernel\n\nAn abstract kernel.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.PseudoDataInducingPoints","page":"API","title":"SparseGaussianProcesses.PseudoDataInducingPoints","text":"PseudoDataInducingPoints\n\nA set of inducing points representing pseudo-data points with diagonal non-constant error covariance.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.PseudoDataInducingPoints-Tuple{AbstractArray{T,2} where T,SparseGaussianProcesses.Kernel}","page":"API","title":"SparseGaussianProcesses.PseudoDataInducingPoints","text":"(self::PseudoDataInducingPoints)(z::AbstractMatrix, k::Kernel)\n\nSets the inducing locations of boldsymbolu to boldsymbolz, inducing mean to zero, and inducing error variance to one for each pseudo-data point.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.PseudoDataInducingPoints-Tuple{SparseGaussianProcesses.Kernel,Int64,Int64}","page":"API","title":"SparseGaussianProcesses.PseudoDataInducingPoints","text":"PseudoDataInducingPoints(k::Kernel, dim::Int, num_inducing::Int)\n\nCreates a set of pseudo-data inducing points with unit error variance.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.PseudoDataInducingPoints-Tuple{}","page":"API","title":"SparseGaussianProcesses.PseudoDataInducingPoints","text":"(self::PseudoDataInducingPoints)()\n\nAssembles the pseudo-data inducing error variance into matrix form. Returns  inducing locations, inducing mean, nothing jitter term, and inducing error variance.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.RandomFeatures","page":"API","title":"SparseGaussianProcesses.RandomFeatures","text":"RandomFeatures\n\nAn abstract set of random features with associated basis weights.\n\n\n\n\n\n","category":"type"},{"location":"api/#SparseGaussianProcesses.num_samples-Tuple{SparseGaussianProcesses.GaussianProcess}","page":"API","title":"SparseGaussianProcesses.num_samples","text":"num_samples(gp::GaussianProcess)\n\nReturns the number of random samples currently stored in gp.\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.pairwise_column_difference-Tuple{AbstractArray{T,2} where T,AbstractArray{T,2} where T}","page":"API","title":"SparseGaussianProcesses.pairwise_column_difference","text":"pairwise_column_difference(x::AbstractMatrix, y::AbstractMatrix)\n\nComputes the 3-dimensional distance array, where out dimensions  are (input_dimension, x_data_point_dimension, y_data_point_dimension).\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.prior_KL-Tuple{SparseGaussianProcess{#s19,#s18,#s17,#s16,#s15,V,H} where H<:SparseGaussianProcesses.Hyperprior where V<:(AbstractArray{T,1} where T) where #s15<:MarginalInducingPoints where #s16 where #s17 where #s18 where #s19}","page":"API","title":"SparseGaussianProcesses.prior_KL","text":"prior_KL(gp::SparseGaussianProcess{<:Any,<:Any,<:Any,<:Any,<:MarginalInducingPoints})\n\nComputes the prior Kullback-Leibler divergence for a Gaussian process  with marginal inducing points, given by the expression\n\nKL(q(boldsymbolu) mathbin p(boldsymbolu)) = frac12 left( lnfracmathbfK_boldsymbolzboldsymbolzmathbfSigma + operatornametr(mathbfK_boldsymbolzboldsymbolz^-1mathbfSigma) + boldsymbolmu^T mathbfK_boldsymbolzboldsymbolz boldsymbolmu right)\n\nwhere the mean is re-parameterized according to boldsymbolmu = mathbbE( (mathbfK_boldsymbolzboldsymbolz + ximathbfI)^-1 boldsymbolu ).\n\n\n\n\n\n","category":"method"},{"location":"api/#SparseGaussianProcesses.spectral_distribution","page":"API","title":"SparseGaussianProcesses.spectral_distribution","text":"spectral_distribution(k::SquaredExponentialKernel, n::Integer = 1)\n\nDraws n samples from the spectral distribution of a standard squared exponential kernel, which is multivariate Gaussian with covariance 2mathbfI.\n\n\n\n\n\n","category":"function"},{"location":"api/#Index-1","page":"API","title":"Index","text":"","category":"section"},{"location":"api/#","page":"API","title":"API","text":"Pages = [\"api.md\"]\nModule = [\"SparseGaussianProcesses\"]","category":"page"},{"location":"#SparseGaussianProcesses.jl-1","page":"Home","title":"SparseGaussianProcesses.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"┌──────────────────────────┐  │⠀⣢⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡆⠀⠀⠀⠀⠀⣤⡤⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│  │⠀⢷⣻⣛⣻⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⢠⣾⣟⢺⣺⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀│  │⠀⣲⣿⣷⣬⣻⣵⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⢀⣶⣿⣽⣿⣯⠽⣿⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀│  │⠀⣿⡾⣿⣿⣻⣷⣧⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⣠⣿⡿⣽⢿⠷⣿⢷⣿⣷⠀⠀⠀⠀⠀⠀⠀⠀⠀│  │⠀⡟⠒⠢⢿⣿⣿⣿⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣧⣿⣾⡿⣳⠓⠒⢬⢻⣟⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀│  │⠀⠀⠀⠀⠈⢺⣿⣿⣧⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⣿⣿⣿⡯⠃⠀⠀⠀⠑⣿⣿⣿⡀⠀⠀⠀⠀⠀⠀⠀│  │⠀⠀⠀⠀⠀⠀⢻⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀⢀⣿⣿⣻⡿⠃⠀⠀⠀⠀⠀⠑⣿⣿⣇⠀⠀⠀⠀⠀⠀⠀│  │⠉⠉⠉⠉⠉⠉⠉⢻⣿⣿⡉⠉⠉⠉⠉⠉⠉⢉⣯⣿⣯⡿⠉⠉⠉⠉⠉⠉⠉⠉⠙⣿⣿⣯⡉⠉⠉⠉⠉⠉│  │⠀⠀⠀⠀⠀⠀⠀⠈⢿⣿⣷⠀⠀⠀⠀⠀⡰⣹⣿⣿⡟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢻⣿⣿⢎⠣⡀⢀⠆⠀│  │⠀⠀⠀⠀⠀⠀⠀⠀⠈⣿⣿⢦⡀⠀⢀⡴⣵⢿⣿⡺⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢏⣿⣧⡣⣸⡃⠀⠀│  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⣾⣿⣷⣺⢝⣠⣿⣿⣿⠃⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢻⣿⣷⣍⣚⡖⠀│  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠹⣿⣿⣿⣿⣿⣿⢿⠇⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢻⣿⢿⣿⣯⠀│  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠿⣭⠿⡿⣫⠃⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⡞⣾⣿⡏⠀│  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠋⠀⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⢅⠀⠀│  │⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠃⠀│  └──────────────────────────┘ ","category":"page"},{"location":"#","page":"Home","title":"Home","text":"A Flux-based package for sparse Gaussian process models in Julia.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"It supports models of the form","category":"page"},{"location":"#","page":"Home","title":"Home","text":"(f mathbin boldsymbolu)(cdot) = (mathcalAg)(cdot) + mathbfK_(cdot)z (mathbfK_zz + mathbfLambda)^-1 (boldsymbolu - (mathcalBg)(boldsymbolz) - boldsymbolepsilon)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"where gsimoperatornameGP(0 k), boldsymbolusimoperatornameN(boldsymbolmu mathbfSigma), boldsymbolepsilonsimoperatornameN(boldsymbol0 mathbfLambda), and mathcalA, mathcalB are inter-domain operators (currently only the identity operator is supported). This little-known formula defines a Gaussian process with precisely the correct mean and covariance of a standard sparse Gaussian process, and can be used to obtain ***entire function draws*** which can be evaluated deterministically at arbitrary locations once sampled. Using this approach, training is performed via doubly stochastic variational inference.","category":"page"},{"location":"#Installation-1","page":"Home","title":"Installation","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"pkg> add SparseGaussianProcesses","category":"page"},{"location":"#Example-1","page":"Home","title":"Example","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"using Flux\nusing SparseGaussianProcesses\n\ngp = SparseGaussianProcess(SquaredExponentialKernel(1))\nx = reshape(-5:0.1:5, (1,:)) |> collect\ny = sin.(x)\n\n(gp,x,y) = gpu.((gp,x,y))\n\nrand!(gp; num_samples = 16)\ngp(x)\n\nopt = ADAM()\ndataset = Iterators.repeated((x,y), 1000)\ncb = Flux.throttle(() -> @show(loss(gp,x,y)|>sum), 1)\n\nFlux.train!((x,y) -> loss(gp,x,y)|>sum, Flux.params(gp), dataset, opt; cb = cb)\n\nimport Plots\nplot_gp_intervals(gp, x, y)","category":"page"},{"location":"#Author-1","page":"Home","title":"Author","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Alexander Terenin (PhD student, Statistical Machine Learning, Imperial College London)","category":"page"},{"location":"#Citing-1","page":"Home","title":"Citing","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"@article{wilson20,\n\tAuthor = {James T. Wilson and Viacheslav Borovitskiy and Alexander Terenin and Peter Mostowski and Marc Peter Deisenroth},\n\tJournal = {arXiv:2002.09309},\n\tTitle = {Efficiently sampling functions from Gaussian process posteriors},\n\tYear = {2020}}\n","category":"page"}]
}
